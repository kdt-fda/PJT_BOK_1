{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9571a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44338b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 전처리\n",
    "def clean_line(line: str) -> str:\n",
    "    line = line.strip()\n",
    "    # PDF 페이지 번호 제거: - 1 -\n",
    "    if re.match(r\"^-\\s*\\d+\\s*-\\s*$\", line):\n",
    "        return \"\"\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245aff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자/특수기호 제거\n",
    "def remove_numbers_symbols(text: str) -> str:\n",
    "    if text is None:\n",
    "        return text\n",
    "\n",
    "    # 숫자 제거 (정수, 소수)\n",
    "    text = re.sub(r\"\\d+(\\.\\d+)?\", \" \", text)\n",
    "\n",
    "    # 퍼센트, 소수점 관련 기호\n",
    "    text = re.sub(r\"[%‰]\", \" \", text)\n",
    "\n",
    "    # 괄호, 따옴표, 슬래시 등 기호 제거\n",
    "    text = re.sub(r\"[()\\[\\]{}<>\\\"']\", \" \", text)\n",
    "\n",
    "    # 마침표, 쉼표 등 문장부호 제거 (토큰화 전에 깔끔하게)\n",
    "    text = re.sub(r\"[.,;:!?…]\", \" \", text)\n",
    "\n",
    "    # 한글/영문 외 문자 제거 \n",
    "    text = re.sub(r\"[^가-힣a-zA-Z\\s]\", \" \", text)\n",
    "\n",
    "    # 공백 정리\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c98cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회의일자 추출 (텍스트 내부)\n",
    "def parse_meeting_date(full_text: str):\n",
    "    m = re.search(\n",
    "        r\"1\\.\\s*일\\s*(?:자|시)\\s*(\\d{4})\\s*년\\s*(\\d{1,2})\\s*월\\s*(\\d{1,2})\\s*일\",\n",
    "        full_text\n",
    "    )\n",
    "    if not m:\n",
    "        return None\n",
    "    y, mth, d = map(int, m.groups())\n",
    "    return f\"{y:04d}-{mth:02d}-{d:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c59bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공개일자 추출 (파일명 기준)\n",
    "def parse_release_date_from_header(header_line: str):\n",
    "    # ---2024.12.24_의사록.pdf---  -> 2024-12-24\n",
    "    m = re.search(r\"(\\d{4})\\.(\\d{2})\\.(\\d{2})\", header_line)\n",
    "    if not m:\n",
    "        return None\n",
    "    y, mth, d = m.groups()\n",
    "    return f\"{y}-{mth}-{d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03179c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_section_titles(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "\n",
    "    # 1) \"(3) 위원 토의내용\" / \"위원 토의내용\" 제거 (어디에 있든)\n",
    "    text = re.sub(r\"(?:\\(\\s*\\d+\\s*\\)\\s*)?위원\\s*토\\s*의\\s*내\\s*용\", \" \", text)\n",
    "\n",
    "    # 2) \"(3) 토의내용\" / \"토의내용\" 제거\n",
    "    text = re.sub(r\"(?:\\(\\s*\\d+\\s*\\)\\s*)?토\\s*의\\s*내\\s*용\", \" \", text)\n",
    "\n",
    "    # 3) 공백 정리\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d89517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가볍게 의사록 분리\n",
    "def split_light_minutes(full_text: str):\n",
    "    # (별첨) 기준 분리\n",
    "    parts = re.split(r\"\\(\\s*별\\s*첨\\s*\\)\", full_text, maxsplit=1)\n",
    "    main_text = parts[0]\n",
    "    appendix = parts[1].strip() if len(parts) == 2 else \"\"\n",
    "\n",
    "    # 토의내용 기준 분리\n",
    "    discussion_re = re.compile(\n",
    "        r\"(?:\\(\\s*\\d+\\s*\\)\\s*)?\"      # (3) 같은 번호가 있어도/없어도\n",
    "        r\"위원\\s*토\\s*의\\s*내\\s*용\"   \n",
    "    )\n",
    "    m_disc = discussion_re.search(main_text)\n",
    "    if m_disc:\n",
    "        meta = main_text[:m_disc.start()].strip()\n",
    "        body_all = main_text[m_disc.start():].strip()\n",
    "    else:\n",
    "        return main_text, \"\", \"\", appendix\n",
    "\n",
    "    # DECISION 판별 패턴 (토의결론 포함)\n",
    "    decision_re = re.compile(\n",
    "        r\"<\\s*(의안|보고)\\s*제|\"\n",
    "        r\"심\\s*의\\s*결\\s*과|\"\n",
    "        r\"토\\s*의\\s*결\\s*론|\"\n",
    "        r\"의\\s*결\\s*사\\s*항|\"\n",
    "        r\"원\\s*안\\s*대\\s*로\\s*가\\s*결|\"\n",
    "        r\"<\\s*붙\\s*임\\s*>\"\n",
    "    )\n",
    "    m_dec = decision_re.search(body_all)\n",
    "    if m_dec:\n",
    "        body = body_all[:m_dec.start()].strip()\n",
    "        decision = body_all[m_dec.start():].strip()\n",
    "    else:\n",
    "        # decision 섹션 못 찾으면 전부 body로\n",
    "        body = body_all.strip()\n",
    "        decision = \"\"\n",
    "\n",
    "    body = remove_section_titles(body)\n",
    "    decision = remove_section_titles(decision)\n",
    "\n",
    "\n",
    "    return meta, body, decision, appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9d19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt 1개 → CSV row 생성\n",
    "def raw_minutes_to_rows(raw_txt_path: str):\n",
    "    with open(raw_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [clean_line(l) for l in f.readlines()]\n",
    "\n",
    "    # 회차 헤더: ---2024.12.24_의사록.pdf---\n",
    "    header_re = re.compile(r\"^---\\s*\\d{4}\\.\\d{2}\\.\\d{2}_.+?---$\")\n",
    "\n",
    "    docs = []\n",
    "    current_header = None\n",
    "    buf = []\n",
    "\n",
    "    for line in lines:\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if header_re.match(line):\n",
    "            # 이전 회차 저장\n",
    "            if current_header is not None:\n",
    "                docs.append((current_header, \" \".join(buf).strip()))\n",
    "            # 새 회차 시작\n",
    "            current_header = line\n",
    "            buf = []\n",
    "        else:\n",
    "            buf.append(line)\n",
    "\n",
    "    # 마지막 회차 저장\n",
    "    if current_header is not None:\n",
    "        docs.append((current_header, \" \".join(buf).strip()))\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for header, text in docs:\n",
    "        release_date = parse_release_date_from_header(header)\n",
    "        meeting_date = parse_meeting_date(text)\n",
    "\n",
    "        meta, body, decision, appendix = split_light_minutes(text)\n",
    "\n",
    "        def add_row(text_type, t):\n",
    "            if t and t.strip():\n",
    "                all_rows.append({\n",
    "                    \"meeting_date\": meeting_date,\n",
    "                    \"release_date\": release_date,\n",
    "                    \"text_date\": release_date,      # 라벨링 기준일\n",
    "                    \"text_type\": text_type,         # META/BODY/DECISION/APPENDIX\n",
    "                    \"text\": t.strip(),\n",
    "                    \"source_type\": \"minutes\"\n",
    "                })\n",
    "\n",
    "        add_row(\"META\", meta)\n",
    "        add_row(\"BODY\", body)\n",
    "        add_row(\"DECISION\", decision)\n",
    "        add_row(\"APPENDIX\", appendix)\n",
    "\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b3bd0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_type\n",
      "META        271\n",
      "BODY        265\n",
      "DECISION    265\n",
      "APPENDIX    141\n",
      "Name: count, dtype: int64\n",
      "    meeting_date release_date\n",
      "0     2011-11-24   2012-01-13\n",
      "3     2011-12-08   2012-01-25\n",
      "7     2011-12-16   2012-01-31\n",
      "8     2011-12-22   2012-02-07\n",
      "11    2011-12-29   2012-02-14\n",
      "..           ...          ...\n",
      "924   2025-09-11   2025-09-30\n",
      "927   2025-09-25   2025-10-17\n",
      "931   2025-10-23   2025-11-11\n",
      "935   2025-11-27   2025-12-16\n",
      "939   2025-12-11   2025-12-30\n",
      "\n",
      "[271 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 실행부: 폴더 내 모든 txt 처리\n",
    "all_rows = raw_minutes_to_rows(\"./minutes_text.txt\")\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str).apply(remove_numbers_symbols)\n",
    "\n",
    "df.to_csv(\"minutes_stage1.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# sanity check\n",
    "print(df[\"text_type\"].value_counts())\n",
    "print(df[[\"meeting_date\", \"release_date\"]].drop_duplicates())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

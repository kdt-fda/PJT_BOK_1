{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ffdb1f",
   "metadata": {},
   "source": [
    "## 페이지 및 pdf 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests beautifulsoup4 tqdm pdfminer.six pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e3f6a",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce9e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "import pandas as pd\n",
    "import fitz\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268e672",
   "metadata": {},
   "source": [
    "### 고정 변수 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63e0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://finance.naver.com\"\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.7,en;q=0.6\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Referer\": BASE,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r\"C:\\Users\\User\\Desktop\\kdt\\pjt_bok_1\"\n",
    "PDF_DIR = os.path.join(BASE_DIR, \"pdf\")\n",
    "TXT_DIR = os.path.join(BASE_DIR, \"text\")\n",
    "DEBUG_DIR = os.path.join(BASE_DIR, \"debug_html\")\n",
    "os.makedirs(PDF_DIR, exist_ok=True)\n",
    "os.makedirs(TXT_DIR, exist_ok=True)\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BROKER_CODE = \"18\"\n",
    "DATE_FROM = \"2012-01-01\" # 필요시 수정\n",
    "DATE_TO = \"2025-12-31\" # 필요시 수정\n",
    "SEARCH_TYPE = \"writeDate\"\n",
    "SLEEP_SEC = 0.3\n",
    "MAX_PAGE = 300 # 필요시 수정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f40f2",
   "metadata": {},
   "source": [
    "### 세션 열기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "}\n",
    "\n",
    "def fetch_html(url: str, referer: str | None = None, max_retries: int = 6) -> str:\n",
    "    headers = DEFAULT_HEADERS.copy()\n",
    "    if referer:\n",
    "        headers[\"Referer\"] = referer\n",
    "\n",
    "    last_err = None\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            r = session.get(\n",
    "                url,\n",
    "                headers=headers,\n",
    "                timeout=(10, 25),   # (connect, read)\n",
    "                allow_redirects=True,\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "\n",
    "            r.encoding = r.apparent_encoding\n",
    "            return r.text\n",
    "\n",
    "        except (requests.exceptions.ConnectionError,\n",
    "                requests.exceptions.Timeout,\n",
    "                requests.exceptions.ChunkedEncodingError,\n",
    "                requests.exceptions.HTTPError) as e:\n",
    "            last_err = e\n",
    "\n",
    "            sleep_sec = min(60, (2 ** attempt)) + random.uniform(0.2, 1.2)\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "    raise last_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c0ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_html(url: str, referer: str | None = None) -> str:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    if referer:\n",
    "        headers[\"Referer\"] = referer\n",
    "\n",
    "    r = session.get(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        timeout=25,\n",
    "        allow_redirects=True,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "\n",
    "    r.encoding = r.apparent_encoding\n",
    "    return r.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5ef58",
   "metadata": {},
   "source": [
    "### 페이지 url 리스트 받는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7701ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_url(page: int) -> str:\n",
    "    return (\n",
    "        f\"{BASE}/research/debenture_list.naver?\"\n",
    "        f\"keyword=&brokerCode={BROKER_CODE}\"\n",
    "        f\"&searchType={SEARCH_TYPE}\"\n",
    "        f\"&writeFromDate={DATE_FROM}&writeToDate={DATE_TO}\"\n",
    "        f\"&x=0&y=0&page={page}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2605222",
   "metadata": {},
   "source": [
    "### nid(고유키) 받는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb68c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "nids = set()\n",
    "def get_list_nids(page: int) -> list[int]:\n",
    "    url = get_list_url(page)\n",
    "    html = fetch_html(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    nids = []\n",
    "    for a in soup.select('a[href*=\"debenture_read.naver?nid=\"]'):\n",
    "        href = a.get(\"href\", \"\")\n",
    "        m = re.search(r\"nid=(\\d+)\", href)\n",
    "        if m:\n",
    "            nids.append(int(m.group(1)))\n",
    "\n",
    "    uniq, seen = [], set()\n",
    "    for x in nids:\n",
    "        if x not in seen:\n",
    "            uniq.append(x)\n",
    "            seen.add(x)\n",
    "    return uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8242f24",
   "metadata": {},
   "source": [
    "### 상세페이지 parse 하기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38c3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_detail_page_raw(nid: int, debug: bool = False) -> dict | None:\n",
    "    list_url = get_list_url(1)\n",
    "    detail_url = f\"{BASE}/research/debenture_read.naver?nid={nid}\"\n",
    "\n",
    "    html = fetch_html(detail_url, referer=list_url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    text_all = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    og = soup.select_one('meta[property=\"og:title\"]')\n",
    "    title = og.get(\"content\").strip() if og and og.get(\"content\") else None\n",
    "\n",
    "    source_p = soup.select_one(\"p.source\")\n",
    "    source_raw = source_p.get_text(\" \", strip=True) if source_p else None\n",
    "\n",
    "    date = None\n",
    "    org = None\n",
    "    if source_raw:\n",
    "        m_date = re.search(r\"(20\\d{2}\\.\\d{2}\\.\\d{2})\", source_raw)\n",
    "        if m_date:\n",
    "            date = m_date.group(1)\n",
    "            org = source_raw.split(date)[0].replace(\"|\", \" \").strip()\n",
    "            org = re.sub(r\"\\s+\", \" \", org)\n",
    "\n",
    "    page_text = None\n",
    "    td_node = soup.select_one(\"#contentarea_left td.view_cnt\")\n",
    "    if td_node:\n",
    "        ps = td_node.select(\"p\")\n",
    "        if ps:\n",
    "            page_text = \"\\n\".join(\n",
    "                p.get_text(\" \", strip=True) for p in ps if p.get_text(strip=True)\n",
    "            )\n",
    "        else:\n",
    "            page_text = td_node.get_text(\"\\n\", strip=True)\n",
    "\n",
    "    if not page_text:\n",
    "        selector = \"#contentarea_left > div.box_type_m.box_type_m3 > table > tbody > tr:nth-child(3) > td > div:nth-child(1) > p\"\n",
    "        p_node = soup.select_one(selector)\n",
    "        if p_node:\n",
    "            page_text = p_node.get_text(\"\\n\", strip=True)\n",
    "\n",
    "    if page_text:\n",
    "        page_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", page_text).strip()\n",
    "\n",
    "    if title == \"네이버페이 증권\" and not date and not page_text:\n",
    "        if debug:\n",
    "            with open(os.path.join(DEBUG_DIR, f\"landing_{nid}.html\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html)\n",
    "        return None\n",
    "\n",
    "    if not (title or source_raw or page_text):\n",
    "        if debug:\n",
    "            with open(os.path.join(DEBUG_DIR, f\"parse_fail_{nid}.html\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html)\n",
    "        return None\n",
    "\n",
    "    pdf_url = None\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "        if \"btn_report.gif\" in str(a):\n",
    "            pdf_url = urljoin(BASE, a.get(\"href\"))\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"nid\": nid,\n",
    "        \"title\": title,\n",
    "        \"org\": org,\n",
    "        \"date\": date,\n",
    "        \"source_raw\": source_raw,\n",
    "        \"page_text\": page_text,\n",
    "        \"pdf_url\": pdf_url,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b5443b",
   "metadata": {},
   "source": [
    "### 파일 이름 안정화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2874a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(s: str, maxlen: int = 180) -> str:\n",
    "    s = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s[:maxlen]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a231b15",
   "metadata": {},
   "source": [
    "### pdf 다운로드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0f5e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(meta: dict) -> str:\n",
    "    filename = f\"{meta['date']}_{meta.get('org') or 'UNKNOWN'}_{meta['nid']}.pdf\"\n",
    "    filename = safe_filename(filename)\n",
    "    path = os.path.join(PDF_DIR, filename)\n",
    "\n",
    "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "        return path\n",
    "\n",
    "    r = session.get(meta[\"pdf_url\"], timeout=60)\n",
    "    r.raise_for_status()\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b35ecd",
   "metadata": {},
   "source": [
    "### pdf에서 text 추출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc021883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join(page.get_text() for page in doc)\n",
    "    doc.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2899e5",
   "metadata": {},
   "source": [
    "### pdf text를 csv 파일에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68f2e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf_text(meta: dict, pdf_path: str, pdf_text: str) -> str:\n",
    "    txt_name = os.path.basename(pdf_path).replace(\".pdf\", \".txt\")\n",
    "    txt_path = os.path.join(TXT_DIR, txt_name)\n",
    "    if not os.path.exists(txt_path):\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pdf_text)\n",
    "    return txt_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29467961",
   "metadata": {},
   "source": [
    "### 네이버 증권 페이지를 df로 변환하는 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63a13cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_all_page_only_to_df() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    page = 1\n",
    "    empty_pages = 0\n",
    "    done = set()\n",
    "    \n",
    "    while True:\n",
    "        if page > MAX_PAGE:\n",
    "            break\n",
    "\n",
    "        nids = get_list_nids(page)\n",
    "\n",
    "        if not nids:\n",
    "            empty_pages += 1\n",
    "            if empty_pages >= 2:\n",
    "                break\n",
    "            page += 1\n",
    "            continue\n",
    "        \n",
    "        empty_pages = 0\n",
    "        for nid in tqdm(nids, desc=f\"page {page}\"):\n",
    "            if nid in done:\n",
    "                continue\n",
    "\n",
    "            meta = parse_detail_page_raw(nid, debug=True)\n",
    "            done.add(nid)\n",
    "            if meta is None:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"nid\": meta[\"nid\"],\n",
    "                \"date\": meta[\"date\"],\n",
    "                \"org\": meta[\"org\"],\n",
    "                \"title\": meta[\"title\"],\n",
    "                \"source_raw\": meta[\"source_raw\"],\n",
    "                \"page_text\": meta[\"page_text\"],\n",
    "            })\n",
    "\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fd26d",
   "metadata": {},
   "source": [
    "### 개별 pdf text를 하나의 text에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec26ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def merge_txt_to_csv_with_nid(input_dir: str, output_csv: str):\n",
    "    input_dir = Path(input_dir)\n",
    "\n",
    "    # ✅ txt 파일 탐색\n",
    "    files = sorted(input_dir.glob(\"*.txt\"))\n",
    "    if len(files) == 0:\n",
    "        raise FileNotFoundError(\n",
    "            f\".txt 파일을 찾지 못했습니다.\\n\"\n",
    "            f\"- input_dir: {input_dir}\\n\"\n",
    "            f\"- 확인: 폴더 경로가 맞는지, 확장자가 정말 .txt인지 확인하세요.\"\n",
    "        )\n",
    "\n",
    "    print(f\"발견한 txt 파일 수: {len(files)}\")\n",
    "    print(\"예시 파일 3개:\", [f.name for f in files[:3]])\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for fp in files:\n",
    "        # ✅ 파일명에서 nid 추출: 마지막 '_' 뒤 숫자\n",
    "        m = re.search(r\"_([0-9]+)$\", fp.stem)\n",
    "        if not m:\n",
    "            raise ValueError(f\"nid 추출 실패(파일명 규칙 확인 필요): {fp.name}\")\n",
    "        nid = m.group(1)\n",
    "\n",
    "        # ✅ 텍스트 읽기 + 줄바꿈 제거(한 줄화)\n",
    "        with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # \\n 포함 모든 공백을 스페이스 하나로 정리\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        rows.append({\"nid\": nid, \"text\": text})\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"nid\", \"text\"])\n",
    "\n",
    "    # ✅ nid 유일성 체크\n",
    "    if df[\"nid\"].duplicated().any():\n",
    "        dup = df.loc[df[\"nid\"].duplicated(keep=False), \"nid\"].value_counts().head(20)\n",
    "        raise ValueError(f\"중복 nid 발견(상위 20개):\\n{dup}\")\n",
    "\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"저장 완료: {output_csv} ({len(df)}개 문서)\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acd98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견한 txt 파일 수: 8836\n",
      "예시 파일 3개: ['2008.04.01_대우증권_12.txt', '2008.04.07_대우증권_11.txt', '2008.04.07_대우증권_33.txt']\n",
      "저장 완료: total_pdf_text2.csv (8836개 문서)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2008_04 월간채권투자 채권시장 전망 금융시장 차트북 對應과限界 월간채권투자 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Fixed Income Weekly 2008. 4. 7. #918 Fixed Inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Fixed Income Weekly 2008. 4. 7. #918 Fixed Inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4월 금통위는 정부-한은간 policy mix 합의의 반영일 수도 예상대로, 올해 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>경기 전망은 비교적 분명… 인플레 명분이 시점 결정할 것 현 금리 레벨이 5월 인하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8831</th>\n",
       "      <td>10264</td>\n",
       "      <td>-2.0 -2.9 1M 12.29 (월) 1d 5d 3.270 2.870 2.939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832</th>\n",
       "      <td>10263</td>\n",
       "      <td>자료 출처: 연합인포맥스, Refinitiv, 유진투자증권 본 자료는 참고용 자료일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8833</th>\n",
       "      <td>10267</td>\n",
       "      <td>2025년 12월 29일 I Global Macro Strategy 하나채권 성장률...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8834</th>\n",
       "      <td>10268</td>\n",
       "      <td>금융투자분석사의 확인 및 중요 공시는 Appendix 참조 받아야 할 $가 사라지면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>10269</td>\n",
       "      <td>전일 주요 채권 관련 기사 1d 5d 1M 10y-3y 43 +1.8 +1.7 AA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8836 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        nid                                               text\n",
       "0        12  2008_04 월간채권투자 채권시장 전망 금융시장 차트북 對應과限界 월간채권투자 4...\n",
       "1        11  Fixed Income Weekly 2008. 4. 7. #918 Fixed Inc...\n",
       "2        33  Fixed Income Weekly 2008. 4. 7. #918 Fixed Inc...\n",
       "3        10  4월 금통위는 정부-한은간 policy mix 합의의 반영일 수도 예상대로, 올해 ...\n",
       "4         9  경기 전망은 비교적 분명… 인플레 명분이 시점 결정할 것 현 금리 레벨이 5월 인하...\n",
       "...     ...                                                ...\n",
       "8831  10264  -2.0 -2.9 1M 12.29 (월) 1d 5d 3.270 2.870 2.939...\n",
       "8832  10263  자료 출처: 연합인포맥스, Refinitiv, 유진투자증권 본 자료는 참고용 자료일...\n",
       "8833  10267  2025년 12월 29일 I Global Macro Strategy 하나채권 성장률...\n",
       "8834  10268  금융투자분석사의 확인 및 중요 공시는 Appendix 참조 받아야 할 $가 사라지면...\n",
       "8835  10269  전일 주요 채권 관련 기사 1d 5d 1M 10y-3y 43 +1.8 +1.7 AA...\n",
       "\n",
       "[8836 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실행\n",
    "merge_txt_to_csv_with_nid(\n",
    "    input_dir=r\"C:\\Users\\User\\Desktop\\kdt\\pjt_bok_1\\text\",\n",
    "    output_csv=\"total_pdf_text.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be2ceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n",
      "This is taking too long, we give up.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nid type 문자열로 변환\n",
    "import csv\n",
    "\n",
    "# CSV 로드\n",
    "df = pd.read_csv(\"total_pdf_text2.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# nid를 문자열로 강제 변환\n",
    "df[\"nid\"] = df[\"nid\"].astype(str)\n",
    "\n",
    "# 따옴표 유지하여 다시 저장\n",
    "df.to_csv(\n",
    "    \"total_pdf_text.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\",\n",
    "    quoting=csv.QUOTE_NONNUMERIC\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2170f",
   "metadata": {},
   "source": [
    "### pdf text를 df 로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d949fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_all_pdf_to_df(include_pdf_text: bool = True) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    page = 1\n",
    "    empty_pages = 0\n",
    "    done = set()\n",
    "\n",
    "    while True:\n",
    "        if page > MAX_PAGE:\n",
    "            break\n",
    "        \n",
    "        nids = get_list_nids(page)\n",
    "        if not nids:\n",
    "            empty_pages += 1\n",
    "            if empty_pages >= 2:\n",
    "                break\n",
    "            page += 1\n",
    "            continue\n",
    "\n",
    "        empty_pages = 0\n",
    "        for nid in tqdm(nids, desc=f\"page {page}\"):\n",
    "            if nid in done:\n",
    "                continue\n",
    "\n",
    "            meta = parse_detail_page_raw(nid, debug=True)\n",
    "            done.add(nid)\n",
    "            if meta is None or not meta.get(\"pdf_url\"):\n",
    "                continue\n",
    "\n",
    "            pdf_path = download_pdf(meta)\n",
    "            pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            txt_path = save_pdf_text(meta, pdf_path, pdf_text)\n",
    "\n",
    "            row = {\n",
    "                \"nid\": meta[\"nid\"],\n",
    "                \"date\": meta[\"date\"],\n",
    "                \"org\": meta[\"org\"],\n",
    "                \"title\": meta[\"title\"],\n",
    "                \"pdf_url\": meta[\"pdf_url\"],\n",
    "                \"pdf_path\": pdf_path,\n",
    "                \"txt_path\": txt_path,\n",
    "            }\n",
    "            if include_pdf_text:\n",
    "                row[\"pdf_text\"] = pdf_text\n",
    "\n",
    "            rows.append(row)\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb294da",
   "metadata": {},
   "source": [
    "### df를 csv로 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c262026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_df_to_csv(df, path):\n",
    "    df.to_csv(\n",
    "        path,\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        lineterminator=\"\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c020f",
   "metadata": {},
   "source": [
    "### 크롤링한 페이지 정보를 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "page 1: 100%|██████████| 2/2 [00:12<00:00,  6.05s/it]\n",
      "page 2: 100%|██████████| 2/2 [00:00<00:00, 330.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 저장 완료 → C:\\Users\\User\\Desktop\\kdt\\pjt_bok_1\\naver_debenture_page_text _.csv\n"
     ]
    }
   ],
   "source": [
    "df_page = crawl_all_page_only_to_df()\n",
    "\n",
    "df_page[\"page_text\"] = (\n",
    "    df_page[\"page_text\"]\n",
    "    .fillna(\"\")\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "save_df_to_csv(df_page, os.path.join(BASE_DIR, \"naver_debenture_page_text.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434271d3",
   "metadata": {},
   "source": [
    "### pdf다운로드 및 text저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_all_pdf_to_df(include_pdf_text=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

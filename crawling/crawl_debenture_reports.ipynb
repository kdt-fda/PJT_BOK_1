{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests beautifulsoup4 tqdm pdfminer.six pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e3f6a",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1ce9e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "import pandas as pd\n",
    "import fitz\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268e672",
   "metadata": {},
   "source": [
    "### 고정 변수 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d63e0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://finance.naver.com\"\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.7,en;q=0.6\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Referer\": BASE,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d36a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r\"C:\\Users\\User\\Desktop\\kdt\\pjt_bok_1\"\n",
    "PDF_DIR = os.path.join(BASE_DIR, \"pdf\")\n",
    "TXT_DIR = os.path.join(BASE_DIR, \"text\")\n",
    "DEBUG_DIR = os.path.join(BASE_DIR, \"debug_html\")\n",
    "os.makedirs(PDF_DIR, exist_ok=True)\n",
    "os.makedirs(TXT_DIR, exist_ok=True)\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d536ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BROKER_CODE = \"18\"\n",
    "DATE_FROM = \"2015-01-01\"\n",
    "DATE_TO = \"2025-12-30\"\n",
    "SEARCH_TYPE = \"writeDate\"\n",
    "SLEEP_SEC = 0.3\n",
    "MAX_PAGE = 260\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f40f2",
   "metadata": {},
   "source": [
    "### 세션 열기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3a93b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#새로운\n",
    "\n",
    "DEFAULT_HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "}\n",
    "\n",
    "def fetch_html(url: str, referer: str | None = None, max_retries: int = 6) -> str:\n",
    "    headers = DEFAULT_HEADERS.copy()\n",
    "    if referer:\n",
    "        headers[\"Referer\"] = referer\n",
    "\n",
    "    last_err = None\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            r = session.get(\n",
    "                url,\n",
    "                headers=headers,\n",
    "                timeout=(10, 25),   # (connect, read)\n",
    "                allow_redirects=True,\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "\n",
    "            # 인코딩은 강제 euc-kr 대신 자동 추정이 더 안전함\n",
    "            r.encoding = r.apparent_encoding\n",
    "            return r.text\n",
    "\n",
    "        except (requests.exceptions.ConnectionError,\n",
    "                requests.exceptions.Timeout,\n",
    "                requests.exceptions.ChunkedEncodingError,\n",
    "                requests.exceptions.HTTPError) as e:\n",
    "            last_err = e\n",
    "\n",
    "            # 지수 백오프 + 랜덤 지터(과부하/차단 회피에 효과적)\n",
    "            sleep_sec = min(60, (2 ** attempt)) + random.uniform(0.2, 1.2)\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "    # 여기까지 오면 완전 실패\n",
    "    raise last_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a0c0ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_html(url: str, referer: str | None = None) -> str:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    if referer:\n",
    "        headers[\"Referer\"] = referer\n",
    "\n",
    "    r = session.get(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        timeout=25,\n",
    "        allow_redirects=True,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "\n",
    "    r.encoding = r.apparent_encoding\n",
    "    return r.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5ef58",
   "metadata": {},
   "source": [
    "### url 리스트 받는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7701ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_url(page: int) -> str:\n",
    "    return (\n",
    "        f\"{BASE}/research/debenture_list.naver?\"\n",
    "        f\"keyword=&brokerCode={BROKER_CODE}\"\n",
    "        f\"&searchType={SEARCH_TYPE}\"\n",
    "        f\"&writeFromDate={DATE_FROM}&writeToDate={DATE_TO}\"\n",
    "        f\"&x=0&y=0&page={page}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2605222",
   "metadata": {},
   "source": [
    "### nid(고유키) 받는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ddb68c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_nids(page: int) -> list[int]:\n",
    "    url = get_list_url(page)\n",
    "    html = fetch_html(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    nids = []\n",
    "    for a in soup.select('a[href*=\"debenture_read.naver?nid=\"]'):\n",
    "        href = a.get(\"href\", \"\")\n",
    "        m = re.search(r\"nid=(\\d+)\", href)\n",
    "        if m:\n",
    "            nids.append(int(m.group(1)))\n",
    "\n",
    "    uniq, seen = [], set()\n",
    "    for x in nids:\n",
    "        if x not in seen:\n",
    "            uniq.append(x)\n",
    "            seen.add(x)\n",
    "    return uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8242f24",
   "metadata": {},
   "source": [
    "### 상세페이지 parse 하기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b38c3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_detail_page_raw(nid: int, debug: bool = False) -> dict | None:\n",
    "    list_url = get_list_url(1)\n",
    "    detail_url = f\"{BASE}/research/debenture_read.naver?nid={nid}\"\n",
    "\n",
    "    html = fetch_html(detail_url, referer=list_url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    text_all = soup.get_text(\" \", strip=True)\n",
    "\n",
    "    og = soup.select_one('meta[property=\"og:title\"]')\n",
    "    title = og.get(\"content\").strip() if og and og.get(\"content\") else None\n",
    "\n",
    "    source_p = soup.select_one(\"p.source\")\n",
    "    source_raw = source_p.get_text(\" \", strip=True) if source_p else None\n",
    "\n",
    "    date = None\n",
    "    org = None\n",
    "    if source_raw:\n",
    "        m_date = re.search(r\"(20\\d{2}\\.\\d{2}\\.\\d{2})\", source_raw)\n",
    "        if m_date:\n",
    "            date = m_date.group(1)\n",
    "            org = source_raw.split(date)[0].replace(\"|\", \" \").strip()\n",
    "            org = re.sub(r\"\\s+\", \" \", org)\n",
    "\n",
    "    page_text = None\n",
    "    td_node = soup.select_one(\"#contentarea_left td.view_cnt\")\n",
    "    if td_node:\n",
    "        ps = td_node.select(\"p\")\n",
    "        if ps:\n",
    "            page_text = \"\\n\".join(\n",
    "                p.get_text(\" \", strip=True) for p in ps if p.get_text(strip=True)\n",
    "            )\n",
    "        else:\n",
    "            page_text = td_node.get_text(\"\\n\", strip=True)\n",
    "\n",
    "    if not page_text:\n",
    "        selector = \"#contentarea_left > div.box_type_m.box_type_m3 > table > tbody > tr:nth-child(3) > td > div:nth-child(1) > p\"\n",
    "        p_node = soup.select_one(selector)\n",
    "        if p_node:\n",
    "            page_text = p_node.get_text(\"\\n\", strip=True)\n",
    "\n",
    "    if page_text:\n",
    "        page_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", page_text).strip()\n",
    "\n",
    "    if title == \"네이버페이 증권\" and not date and not page_text:\n",
    "        if debug:\n",
    "            with open(os.path.join(DEBUG_DIR, f\"landing_{nid}.html\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html)\n",
    "        return None\n",
    "\n",
    "    if not (title or source_raw or page_text):\n",
    "        if debug:\n",
    "            with open(os.path.join(DEBUG_DIR, f\"parse_fail_{nid}.html\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html)\n",
    "        return None\n",
    "\n",
    "    pdf_url = None\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "        if \"btn_report.gif\" in str(a):\n",
    "            pdf_url = urljoin(BASE, a.get(\"href\"))\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"nid\": nid,\n",
    "        \"title\": title,\n",
    "        \"org\": org,\n",
    "        \"date\": date,\n",
    "        \"source_raw\": source_raw,\n",
    "        \"page_text\": page_text,\n",
    "        \"pdf_url\": pdf_url,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b5443b",
   "metadata": {},
   "source": [
    "### 파일 이름 안정화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a2874a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(s: str, maxlen: int = 180) -> str:\n",
    "    s = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s[:maxlen]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a231b15",
   "metadata": {},
   "source": [
    "### pdf 다운로드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a0f5e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(meta: dict) -> str:\n",
    "    filename = f\"{meta['date']}_{meta.get('org') or 'UNKNOWN'}_{meta['nid']}.pdf\"\n",
    "    filename = safe_filename(filename)\n",
    "    path = os.path.join(PDF_DIR, filename)\n",
    "\n",
    "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "        return path\n",
    "\n",
    "    r = session.get(meta[\"pdf_url\"], timeout=60)\n",
    "    r.raise_for_status()\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b35ecd",
   "metadata": {},
   "source": [
    "### pdf에서 text 추출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "dc021883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join(page.get_text() for page in doc)\n",
    "    doc.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2899e5",
   "metadata": {},
   "source": [
    "### text를 csv 파일에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "68f2e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf_text(meta: dict, pdf_path: str, pdf_text: str) -> str:\n",
    "    txt_name = os.path.basename(pdf_path).replace(\".pdf\", \".txt\")\n",
    "    txt_path = os.path.join(TXT_DIR, txt_name)\n",
    "    if not os.path.exists(txt_path):\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pdf_text)\n",
    "    return txt_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29467961",
   "metadata": {},
   "source": [
    "### 네이버 증권 페이지를 df로 변환하는 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "63a13cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_all_page_only_to_df() -> pd.DataFrame:\n",
    "    rows = []\n",
    "    page = 1\n",
    "    empty_pages = 0\n",
    "    done = set()\n",
    "    \n",
    "    while True:\n",
    "        if page > MAX_PAGE:\n",
    "            break\n",
    "\n",
    "        nids = get_list_nids(page)\n",
    "\n",
    "        if not nids:\n",
    "            empty_pages += 1\n",
    "            if empty_pages >= 2:\n",
    "                break\n",
    "            page += 1\n",
    "            continue\n",
    "        \n",
    "        empty_pages = 0\n",
    "        for nid in tqdm(nids, desc=f\"page {page}\"):\n",
    "            if nid in done:\n",
    "                continue\n",
    "\n",
    "            meta = parse_detail_page_raw(nid, debug=True)\n",
    "            done.add(nid)\n",
    "            if meta is None:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"nid\": meta[\"nid\"],\n",
    "                \"date\": meta[\"date\"],\n",
    "                \"org\": meta[\"org\"],\n",
    "                \"title\": meta[\"title\"],\n",
    "                \"source_raw\": meta[\"source_raw\"],\n",
    "                \"page_text\": meta[\"page_text\"],\n",
    "            })\n",
    "\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2170f",
   "metadata": {},
   "source": [
    "### pdf text를 df 로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a6d949fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_all_pdf_to_df(include_pdf_text: bool = True) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    page = 1\n",
    "    empty_pages = 0\n",
    "    done = set()\n",
    "\n",
    "    while True:\n",
    "        nids = get_list_nids(page)\n",
    "        if not nids:\n",
    "            empty_pages += 1\n",
    "            if empty_pages >= 2:\n",
    "                break\n",
    "            page += 1\n",
    "            continue\n",
    "\n",
    "        empty_pages = 0\n",
    "        for nid in tqdm(nids, desc=f\"page {page}\"):\n",
    "            if nid in done:\n",
    "                continue\n",
    "\n",
    "            meta = parse_detail_page_raw(nid, debug=True)\n",
    "            done.add(nid)\n",
    "            if meta is None or not meta.get(\"pdf_url\"):\n",
    "                continue\n",
    "\n",
    "            pdf_path = download_pdf(meta)\n",
    "            pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            txt_path = save_pdf_text(meta, pdf_path, pdf_text)\n",
    "\n",
    "            row = {\n",
    "                \"nid\": meta[\"nid\"],\n",
    "                \"date\": meta[\"date\"],\n",
    "                \"org\": meta[\"org\"],\n",
    "                \"title\": meta[\"title\"],\n",
    "                \"pdf_url\": meta[\"pdf_url\"],\n",
    "                \"pdf_path\": pdf_path,\n",
    "                \"txt_path\": txt_path,\n",
    "            }\n",
    "            if include_pdf_text:\n",
    "                row[\"pdf_text\"] = pdf_text\n",
    "\n",
    "            rows.append(row)\n",
    "            time.sleep(SLEEP_SEC)\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb294da",
   "metadata": {},
   "source": [
    "### df를 csv로 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9c262026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_df_to_csv(df, path):\n",
    "    df.to_csv(\n",
    "        path,\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        lineterminator=\"\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c020f",
   "metadata": {},
   "source": [
    "### 크롤링한 페이지 정보를 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "550d2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "page 1: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 2: 100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "page 3: 100%|██████████| 30/30 [00:15<00:00,  1.99it/s]\n",
      "page 4: 100%|██████████| 30/30 [00:14<00:00,  2.03it/s]\n",
      "page 5: 100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "page 6: 100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "page 7: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 8: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 9: 100%|██████████| 30/30 [00:14<00:00,  2.04it/s]\n",
      "page 10: 100%|██████████| 30/30 [00:14<00:00,  2.01it/s]\n",
      "page 11: 100%|██████████| 30/30 [00:14<00:00,  2.10it/s]\n",
      "page 12: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 13: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 14: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 15: 100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "page 16: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 17: 100%|██████████| 30/30 [00:14<00:00,  2.08it/s]\n",
      "page 18: 100%|██████████| 30/30 [06:57<00:00, 13.90s/it]\n",
      "page 19: 100%|██████████| 30/30 [00:15<00:00,  1.90it/s]\n",
      "page 20: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 21: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 22: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 23: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 24: 100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "page 25: 100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "page 26: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 27: 100%|██████████| 30/30 [00:13<00:00,  2.26it/s]\n",
      "page 28: 100%|██████████| 30/30 [00:15<00:00,  2.00it/s]\n",
      "page 29: 100%|██████████| 30/30 [00:13<00:00,  2.30it/s]\n",
      "page 30: 100%|██████████| 30/30 [00:13<00:00,  2.24it/s]\n",
      "page 31: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 32: 100%|██████████| 30/30 [01:39<00:00,  3.31s/it]\n",
      "page 33: 100%|██████████| 30/30 [00:14<00:00,  2.05it/s]\n",
      "page 34: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 35: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 36: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 37: 100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "page 38: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 39: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 40: 100%|██████████| 30/30 [00:14<00:00,  2.10it/s]\n",
      "page 41: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 42: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 43: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 44: 100%|██████████| 30/30 [00:14<00:00,  2.05it/s]\n",
      "page 45: 100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "page 46: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 47: 100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "page 48: 100%|██████████| 30/30 [00:32<00:00,  1.09s/it]\n",
      "page 49: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 50: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 51: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 52: 100%|██████████| 30/30 [00:13<00:00,  2.24it/s]\n",
      "page 53: 100%|██████████| 30/30 [00:13<00:00,  2.24it/s]\n",
      "page 54: 100%|██████████| 30/30 [00:14<00:00,  2.11it/s]\n",
      "page 55: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 56: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 57: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 58: 100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n",
      "page 59: 100%|██████████| 30/30 [00:13<00:00,  2.26it/s]\n",
      "page 60: 100%|██████████| 30/30 [00:12<00:00,  2.32it/s]\n",
      "page 61: 100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n",
      "page 62: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n",
      "page 63: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 64: 100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "page 65: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 66: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 67: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 68: 100%|██████████| 30/30 [00:12<00:00,  2.37it/s]\n",
      "page 69: 100%|██████████| 30/30 [00:12<00:00,  2.36it/s]\n",
      "page 70: 100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "page 71: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 72: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 73: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 74: 100%|██████████| 30/30 [00:13<00:00,  2.31it/s]\n",
      "page 75: 100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "page 76: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 77: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 78: 100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "page 79: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 80: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 81: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 82: 100%|██████████| 30/30 [00:14<00:00,  2.09it/s]\n",
      "page 83: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 84: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 85: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 86: 100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "page 87: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 88: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 89: 100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "page 90: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 91: 100%|██████████| 30/30 [00:14<00:00,  2.06it/s]\n",
      "page 92: 100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "page 93: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 94: 100%|██████████| 30/30 [00:13<00:00,  2.24it/s]\n",
      "page 95: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 96: 100%|██████████| 30/30 [03:10<00:00,  6.35s/it]\n",
      "page 97: 100%|██████████| 30/30 [00:14<00:00,  2.08it/s]\n",
      "page 98: 100%|██████████| 30/30 [00:14<00:00,  2.09it/s]\n",
      "page 99: 100%|██████████| 30/30 [00:14<00:00,  2.05it/s]\n",
      "page 100: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 101: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 102: 100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "page 103: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 104: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n",
      "page 105: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 106: 100%|██████████| 30/30 [00:13<00:00,  2.24it/s]\n",
      "page 107: 100%|██████████| 30/30 [00:12<00:00,  2.35it/s]\n",
      "page 108: 100%|██████████| 30/30 [00:15<00:00,  1.93it/s]\n",
      "page 109: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 110: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 111: 100%|██████████| 30/30 [00:12<00:00,  2.31it/s]\n",
      "page 112: 100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "page 113: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 114: 100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "page 115: 100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "page 116: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 117: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 118: 100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "page 119: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 120: 100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "page 121: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 122: 100%|██████████| 30/30 [00:12<00:00,  2.35it/s]\n",
      "page 123: 100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "page 124: 100%|██████████| 30/30 [00:14<00:00,  2.05it/s]\n",
      "page 125: 100%|██████████| 30/30 [00:14<00:00,  2.09it/s]\n",
      "page 126: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 127: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 128: 100%|██████████| 30/30 [00:13<00:00,  2.26it/s]\n",
      "page 129: 100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "page 130: 100%|██████████| 30/30 [05:16<00:00, 10.53s/it]\n",
      "page 131: 100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "page 132: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 133: 100%|██████████| 30/30 [00:12<00:00,  2.31it/s]\n",
      "page 134: 100%|██████████| 30/30 [00:13<00:00,  2.24it/s]\n",
      "page 135: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 136: 100%|██████████| 30/30 [00:13<00:00,  2.30it/s]\n",
      "page 137: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 138: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 139: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 140: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 141: 100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "page 142: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 143: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 144: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 145: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 146: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 147: 100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n",
      "page 148: 100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "page 149: 100%|██████████| 30/30 [00:14<00:00,  2.09it/s]\n",
      "page 150: 100%|██████████| 30/30 [00:12<00:00,  2.32it/s]\n",
      "page 151: 100%|██████████| 30/30 [00:57<00:00,  1.93s/it]\n",
      "page 152: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 153: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 154: 100%|██████████| 30/30 [00:12<00:00,  2.38it/s]\n",
      "page 155: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 156: 100%|██████████| 30/30 [00:12<00:00,  2.31it/s]\n",
      "page 157: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 158: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 159: 100%|██████████| 30/30 [00:12<00:00,  2.31it/s]\n",
      "page 160: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 161: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 162: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 163: 100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n",
      "page 164: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n",
      "page 165: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 166: 100%|██████████| 30/30 [00:12<00:00,  2.33it/s]\n",
      "page 167: 100%|██████████| 30/30 [00:12<00:00,  2.39it/s]\n",
      "page 168: 100%|██████████| 30/30 [00:14<00:00,  2.11it/s]\n",
      "page 169: 100%|██████████| 30/30 [00:13<00:00,  2.14it/s]\n",
      "page 170: 100%|██████████| 30/30 [00:13<00:00,  2.28it/s]\n",
      "page 171: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 172: 100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n",
      "page 173: 100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "page 174: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n",
      "page 175: 100%|██████████| 30/30 [00:12<00:00,  2.36it/s]\n",
      "page 176: 100%|██████████| 30/30 [00:12<00:00,  2.35it/s]\n",
      "page 177: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 178: 100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n",
      "page 179: 100%|██████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "page 180: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 181: 100%|██████████| 30/30 [00:15<00:00,  1.99it/s]\n",
      "page 182: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 183: 100%|██████████| 30/30 [00:15<00:00,  1.98it/s]\n",
      "page 184: 100%|██████████| 30/30 [00:15<00:00,  1.98it/s]\n",
      "page 185: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 186: 100%|██████████| 30/30 [00:16<00:00,  1.77it/s]\n",
      "page 187: 100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "page 188: 100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n",
      "page 189: 100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "page 190: 100%|██████████| 30/30 [00:12<00:00,  2.38it/s]\n",
      "page 191: 100%|██████████| 30/30 [00:12<00:00,  2.43it/s]\n",
      "page 192: 100%|██████████| 30/30 [00:12<00:00,  2.39it/s]\n",
      "page 193: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 194: 100%|██████████| 30/30 [00:12<00:00,  2.36it/s]\n",
      "page 195: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 196: 100%|██████████| 30/30 [00:12<00:00,  2.45it/s]\n",
      "page 197: 100%|██████████| 30/30 [00:12<00:00,  2.32it/s]\n",
      "page 198: 100%|██████████| 30/30 [00:12<00:00,  2.38it/s]\n",
      "page 199: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 200: 100%|██████████| 30/30 [00:16<00:00,  1.81it/s]\n",
      "page 201: 100%|██████████| 30/30 [00:12<00:00,  2.31it/s]\n",
      "page 202: 100%|██████████| 30/30 [00:13<00:00,  2.22it/s]\n",
      "page 203: 100%|██████████| 30/30 [00:15<00:00,  1.96it/s]\n",
      "page 204: 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]\n",
      "page 205: 100%|██████████| 30/30 [00:14<00:00,  2.06it/s]\n",
      "page 206: 100%|██████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "page 207: 100%|██████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "page 208: 100%|██████████| 30/30 [00:13<00:00,  2.16it/s]\n",
      "page 209: 100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "page 210: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n",
      "page 211: 100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n",
      "page 212: 100%|██████████| 30/30 [00:13<00:00,  2.20it/s]\n",
      "page 213: 100%|██████████| 30/30 [00:13<00:00,  2.21it/s]\n",
      "page 214: 100%|██████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "page 215: 100%|██████████| 30/30 [00:16<00:00,  1.80it/s]\n",
      "page 216: 100%|██████████| 30/30 [00:17<00:00,  1.74it/s]\n",
      "page 217: 100%|██████████| 30/30 [00:15<00:00,  1.95it/s]\n",
      "page 218: 100%|██████████| 30/30 [00:15<00:00,  1.93it/s]\n",
      "page 219: 100%|██████████| 30/30 [00:13<00:00,  2.15it/s]\n",
      "page 220: 100%|██████████| 30/30 [00:15<00:00,  1.89it/s]\n",
      "page 221: 100%|██████████| 30/30 [00:15<00:00,  1.98it/s]\n",
      "page 222: 100%|██████████| 30/30 [00:15<00:00,  1.91it/s]\n",
      "page 223: 100%|██████████| 30/30 [00:15<00:00,  1.96it/s]\n",
      "page 224: 100%|██████████| 30/30 [00:14<00:00,  2.04it/s]\n",
      "page 225: 100%|██████████| 30/30 [00:14<00:00,  2.04it/s]\n",
      "page 226: 100%|██████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "page 227: 100%|██████████| 30/30 [00:15<00:00,  1.91it/s]\n",
      "page 228: 100%|██████████| 30/30 [00:15<00:00,  1.94it/s]\n",
      "page 229: 100%|██████████| 30/30 [00:15<00:00,  1.97it/s]\n",
      "page 230: 100%|██████████| 30/30 [00:15<00:00,  1.93it/s]\n",
      "page 231: 100%|██████████| 30/30 [00:15<00:00,  1.97it/s]\n",
      "page 232: 100%|██████████| 30/30 [00:15<00:00,  1.94it/s]\n",
      "page 233: 100%|██████████| 30/30 [00:16<00:00,  1.82it/s]\n",
      "page 234: 100%|██████████| 30/30 [00:15<00:00,  1.92it/s]\n",
      "page 235: 100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n",
      "page 236: 100%|██████████| 30/30 [00:16<00:00,  1.86it/s]\n",
      "page 237: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s]\n",
      "page 238: 100%|██████████| 30/30 [00:19<00:00,  1.56it/s]\n",
      "page 239: 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n",
      "page 240: 100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n",
      "page 241: 100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n",
      "page 242: 100%|██████████| 30/30 [00:19<00:00,  1.51it/s]\n",
      "page 243: 100%|██████████| 30/30 [00:17<00:00,  1.70it/s]\n",
      "page 244: 100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "page 245: 100%|██████████| 30/30 [00:19<00:00,  1.54it/s]\n",
      "page 246: 100%|██████████| 30/30 [00:17<00:00,  1.73it/s]\n",
      "page 247: 100%|██████████| 30/30 [00:15<00:00,  1.91it/s]\n",
      "page 248: 100%|██████████| 30/30 [00:15<00:00,  1.96it/s]\n",
      "page 249: 100%|██████████| 30/30 [00:15<00:00,  1.88it/s]\n",
      "page 250: 100%|██████████| 30/30 [00:15<00:00,  1.91it/s]\n",
      "page 251: 100%|██████████| 30/30 [00:16<00:00,  1.87it/s]\n",
      "page 252: 100%|██████████| 30/30 [00:15<00:00,  1.92it/s]\n",
      "page 253: 100%|██████████| 30/30 [00:16<00:00,  1.85it/s]\n",
      "page 254: 100%|██████████| 30/30 [00:15<00:00,  1.95it/s]\n",
      "page 255: 100%|██████████| 30/30 [00:16<00:00,  1.86it/s]\n",
      "page 256: 100%|██████████| 30/30 [00:16<00:00,  1.78it/s]\n",
      "page 257: 100%|██████████| 30/30 [00:15<00:00,  1.92it/s]\n",
      "page 258: 100%|██████████| 30/30 [00:15<00:00,  1.92it/s]\n",
      "page 259: 100%|██████████| 30/30 [00:12<00:00,  2.44it/s]\n",
      "page 260: 100%|██████████| 8/8 [00:03<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "df_page = crawl_all_page_only_to_df()\n",
    "\n",
    "df_page[\"page_text\"] = (\n",
    "    df_page[\"page_text\"]\n",
    "    .fillna(\"\")\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "save_df_to_csv(df_page, os.path.join(BASE_DIR, \"naver_debenture_page_text.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434271d3",
   "metadata": {},
   "source": [
    "### 크롤링한 pdf 정보를 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e9c41",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'study (Python 3.12.12)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. listen EFAULT: bad address in system call argument 127.0.0.1:9006"
     ]
    }
   ],
   "source": [
    "df_pdf = crawl_all_pdf_to_df(include_pdf_text=True)\n",
    "save_df_to_csv(df_pdf, os.path.join(BASE_DIR, \"naver_debenture_pdf_text.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
